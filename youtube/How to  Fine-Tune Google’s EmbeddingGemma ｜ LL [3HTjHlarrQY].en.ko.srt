<transcript>
1
00:00:00,080 --> 00:00:02,070
임베딩. 이것들은 당신이 지금까지 사용해본

2
00:00:02,070 --> 00:00:02,080
임베딩. 이것들은 당신이 지금까지 사용해본

3
00:00:02,080 --> 00:00:04,630
임베딩. 이것들은 당신이 지금까지 사용해본
모든 스마트 AI 앱들의 비밀 소스입니다.

4
00:00:04,630 --> 00:00:04,640
모든 스마트 AI 앱들의 비밀 소스입니다.

5
00:00:04,640 --> 00:00:08,470
모든 스마트 AI 앱들의 비밀 소스입니다.
구글 검색부터 ChatGPT까지

6
00:00:08,470 --> 00:00:08,480
구글 검색부터 ChatGPT까지

7
00:00:08,480 --> 00:00:11,350
구글 검색부터 ChatGPT까지
메모리부터 당신이 원하는 것을

8
00:00:11,350 --> 00:00:11,360
메모리부터 당신이 원하는 것을

9
00:00:11,360 --> 00:00:14,310
메모리부터 당신이 원하는 것을
정확히 아는 추천 피드까지 말입니다.

10
00:00:14,310 --> 00:00:14,320
정확히 아는 추천 피드까지 말입니다.

11
00:00:14,320 --> 00:00:16,630
정확히 아는 추천 피드까지 말입니다.
하지만 여기 함정이 있습니다. 대부분의

12
00:00:16,630 --> 00:00:16,640
하지만 여기 함정이 있습니다. 대부분의

13
00:00:16,640 --> 00:00:18,790
하지만 여기 함정이 있습니다. 대부분의
임베딩 모델들은 로컬에서 실행하기엔

14
00:00:18,790 --> 00:00:18,800
임베딩 모델들은 로컬에서 실행하기엔

15
00:00:18,800 --> 00:00:21,349
임베딩 모델들은 로컬에서 실행하기엔
너무 크거나 당신의 데이터에 적용하기엔

16
00:00:21,349 --> 00:00:21,359
너무 크거나 당신의 데이터에 적용하기엔

17
00:00:21,359 --> 00:00:24,390
너무 크거나 당신의 데이터에 적용하기엔
너무 일반적입니다. 여기서 구글의 새로운

18
00:00:24,390 --> 00:00:24,400
너무 일반적입니다. 여기서 구글의 새로운

19
00:00:24,400 --> 00:00:27,269
너무 일반적입니다. 여기서 구글의 새로운
임베딩 Gemma가 게임을 바꿉니다.

20
00:00:27,269 --> 00:00:27,279
임베딩 Gemma가 게임을 바꿉니다.

21
00:00:27,279 --> 00:00:30,390
임베딩 Gemma가 게임을 바꿉니다.
단지 3억 800만 개의 파라미터로, 이 작은

22
00:00:30,390 --> 00:00:30,400
단지 3억 800만 개의 파라미터로, 이 작은

23
00:00:30,400 --> 00:00:33,270
단지 3억 800만 개의 파라미터로, 이 작은
괴물은 당신의 노트북에서 오프라인으로 실행되거나

24
00:00:33,270 --> 00:00:33,280
괴물은 당신의 노트북에서 오프라인으로 실행되거나

25
00:00:33,280 --> 00:00:36,389
괴물은 당신의 노트북에서 오프라인으로 실행되거나
심지어 당신의 휴대폰에서도 실행되면서도 여전히

26
00:00:36,389 --> 00:00:36,399
심지어 당신의 휴대폰에서도 실행되면서도 여전히

27
00:00:36,399 --> 00:00:38,869
심지어 당신의 휴대폰에서도 실행되면서도 여전히
두 배 크기의 모델을 업계

28
00:00:38,869 --> 00:00:38,879
두 배 크기의 모델을 업계

29
00:00:38,879 --> 00:00:41,590
두 배 크기의 모델을 업계
골드 스탠다드 벤치마크에서 능가합니다. 그리고

30
00:00:41,590 --> 00:00:41,600
골드 스탠다드 벤치마크에서 능가합니다. 그리고

31
00:00:41,600 --> 00:00:43,990
골드 스탠다드 벤치마크에서 능가합니다. 그리고
이 비디오에서, 저는 당신에게

32
00:00:43,990 --> 00:00:44,000
이 비디오에서, 저는 당신에게

33
00:00:44,000 --> 00:00:46,069
이 비디오에서, 저는 당신에게
구글이 문서에서 가르쳐주지 않는

34
00:00:46,069 --> 00:00:46,079
구글이 문서에서 가르쳐주지 않는

35
00:00:46,079 --> 00:00:49,750
구글이 문서에서 가르쳐주지 않는
것을 보여드리겠습니다. 임베딩 Gemma를

36
00:00:49,750 --> 00:00:49,760
것을 보여드리겠습니다. 임베딩 Gemma를

37
00:00:49,760 --> 00:00:52,950
것을 보여드리겠습니다. 임베딩 Gemma를
당신만의 데이터셋에 파인튜닝하는 방법을요. 상상해보세요

38
00:00:52,950 --> 00:00:52,960
당신만의 데이터셋에 파인튜닝하는 방법을요. 상상해보세요

39
00:00:52,960 --> 00:00:55,430
당신만의 데이터셋에 파인튜닝하는 방법을요. 상상해보세요
이런 상황을, 당신이 수천 개의 고객

40
00:00:55,430 --> 00:00:55,440
이런 상황을, 당신이 수천 개의 고객

41
00:00:55,440 --> 00:00:58,069
이런 상황을, 당신이 수천 개의 고객
지원 채팅, 연구 논문 또는 심지어

42
00:00:58,069 --> 00:00:58,079
지원 채팅, 연구 논문 또는 심지어

43
00:00:58,079 --> 00:01:00,549
지원 채팅, 연구 논문 또는 심지어
당신의 개인 노트들을 가지고 있다고 말입니다. 일반적인

44
00:00:00,549 --> 00:01:00,559
당신의 개인 노트들을 가지고 있다고 말입니다. 일반적인

45
00:01:00,559 --> 00:01:03,029
당신의 개인 노트들을 가지고 있다고 말입니다. 일반적인
임베딩에 의존하는 대신, 우리는 Gemma를 훈련시켜

46
00:01:03,029 --> 00:01:03,039
임베딩에 의존하는 대신, 우리는 Gemma를 훈련시켜

47
00:01:03,039 --> 00:01:06,230
임베딩에 의존하는 대신, 우리는 Gemma를 훈련시켜
특정 도메인 언어를 이해하도록 할 것입니다. 그래서

48
00:01:06,230 --> 00:01:06,240
특정 도메인 언어를 이해하도록 할 것입니다. 그래서

49
00:01:06,240 --> 00:01:10,070
특정 도메인 언어를 이해하도록 할 것입니다. 그래서
당신의 AI 앱이 질문에 더 정확하게

50
00:01:10,070 --> 00:01:10,080
당신의 AI 앱이 질문에 더 정확하게

51
00:01:10,080 --> 00:01:13,590
당신의 AI 앱이 질문에 더 정확하게
대답하고, 더 나은 컨텍스트를 추천하거나

52
00:01:13,590 --> 00:01:13,600
대답하고, 더 나은 컨텍스트를 추천하거나

53
00:01:13,600 --> 00:01:15,510
대답하고, 더 나은 컨텍스트를 추천하거나
심지어 당신의 파일을 위한

54
00:01:15,510 --> 00:01:15,520
심지어 당신의 파일을 위한

55
00:01:15,520 --> 00:01:17,429
심지어 당신의 파일을 위한
개인 오프라인 검색 엔진이 될 수 있습니다.

56
00:01:17,429 --> 00:01:17,439
개인 오프라인 검색 엔진이 될 수 있습니다.

57
00:01:17,439 --> 00:01:19,990
개인 오프라인 검색 엔진이 될 수 있습니다.
그러니 계속 보세요. 튜토리얼이 끝나면

58
00:01:19,990 --> 00:01:20,000
그러니 계속 보세요. 튜토리얼이 끝나면

59
00:01:20,000 --> 00:01:22,230
그러니 계속 보세요. 튜토리얼이 끝나면
Gemma를 파인튜닝하는 방법뿐만 아니라

60
00:01:22,230 --> 00:01:22,240
Gemma를 파인튜닝하는 방법뿐만 아니라

61
00:01:22,240 --> 00:01:24,950
Gemma를 파인튜닝하는 방법뿐만 아니라
당신의 임베딩을 평가하는 방법까지 알게 될 것입니다.

62
00:01:24,950 --> 00:01:24,960
당신의 임베딩을 평가하는 방법까지 알게 될 것입니다.

63
00:01:24,960 --> 00:01:29,030
당신의 임베딩을 평가하는 방법까지 알게 될 것입니다.
그래서 당신은 그냥 작동한다고 추측하는 것이 아니라

64
00:01:29,030 --> 00:01:29,040
그래서 당신은 그냥 작동한다고 추측하는 것이 아니라

65
00:01:29,040 --> 00:01:31,990
그래서 당신은 그냥 작동한다고 추측하는 것이 아니라
실제로 증명할 수 있습니다.

66
00:01:31,990 --> 00:01:32,000
실제로 증명할 수 있습니다.

67
00:01:32,000 --> 00:01:34,630
실제로 증명할 수 있습니다.
좋습니다. 시작해보겠습니다. 이제

68
00:01:34,630 --> 00:01:34,640
좋습니다. 시작해보겠습니다. 이제

69
00:01:34,640 --> 00:01:39,190
좋습니다. 시작해보겠습니다. 이제
이 모델의 훈련을 시작해보겠습니다. 우리는

70
00:01:39,190 --> 00:01:39,200
이 모델의 훈련을 시작해보겠습니다. 우리는

71
00:01:39,200 --> 00:01:41,910
이 모델의 훈련을 시작해보겠습니다. 우리는
우리의 커스텀 데이터셋에 대해 훈련할 것입니다.

72
00:01:41,910 --> 00:01:41,920
우리의 커스텀 데이터셋에 대해 훈련할 것입니다.

73
00:01:41,920 --> 00:01:44,870
우리의 커스텀 데이터셋에 대해 훈련할 것입니다.
이를 위해서는 GPU 서버에서 실행하고 있는지

74
00:01:44,870 --> 00:01:44,880
이를 위해서는 GPU 서버에서 실행하고 있는지

75
00:01:44,880 --> 00:01:48,069
이를 위해서는 GPU 서버에서 실행하고 있는지
확인해야 합니다. T4가 선택되었는지

76
00:01:48,069 --> 00:01:48,079
확인해야 합니다. T4가 선택되었는지

77
00:01:48,079 --> 00:01:50,710
확인해야 합니다. T4가 선택되었는지
확인하고 필요한 종속성을

78
00:01:50,710 --> 00:01:50,720
확인하고 필요한 종속성을

79
00:01:50,720 --> 00:01:54,469
확인하고 필요한 종속성을
설치하세요.

80
00:01:54,469 --> 00:01:54,479
설치하세요.

81
00:01:54,479 --> 00:01:56,870
설치하세요.
이 종속성 설치에는 약 1-2분 정도

82
00:01:56,870 --> 00:01:56,880
이 종속성 설치에는 약 1-2분 정도

83
00:01:56,880 --> 00:01:59,830
이 종속성 설치에는 약 1-2분 정도
걸릴 것입니다. 완료되면,

84
00:01:59,830 --> 00:01:59,840
걸릴 것입니다. 완료되면,

85
00:01:59,840 --> 00:02:03,590
걸릴 것입니다. 완료되면,
버전이 URL에 제가 작성한 것과

86
00:02:03,590 --> 00:02:03,600
버전이 URL에 제가 작성한 것과

87
00:02:03,600 --> 00:02:07,910
버전이 URL에 제가 작성한 것과
올바른지 확인해야 합니다.

88
00:02:07,910 --> 00:02:07,920
올바른지 확인해야 합니다.

89
00:02:07,920 --> 00:02:11,029
올바른지 확인해야 합니다.
이제 이것을 지우고 Hugging Face에

90
00:02:11,029 --> 00:02:11,039
이제 이것을 지우고 Hugging Face에

91
00:02:11,039 --> 00:02:13,110
이제 이것을 지우고 Hugging Face에
로그인해보겠습니다. 토큰을

92
00:02:13,110 --> 00:02:13,120
로그인해보겠습니다. 토큰을

93
00:02:13,120 --> 00:02:15,830
로그인해보겠습니다. 토큰을
제공해야 합니다.

94
00:02:15,830 --> 00:02:15,840
제공해야 합니다.

95
00:02:15,840 --> 00:02:18,550
제공해야 합니다.
완료되면 구글 임베딩 3억 개

96
00:02:18,550 --> 00:02:18,560
완료되면 구글 임베딩 3억 개

97
00:02:18,560 --> 00:02:21,910
완료되면 구글 임베딩 3억 개
파라미터 모델에서 모델을 다운로드할 수 있습니다.

98
00:02:21,910 --> 00:02:21,920
파라미터 모델에서 모델을 다운로드할 수 있습니다.

99
00:02:21,920 --> 00:02:25,030
파라미터 모델에서 모델을 다운로드할 수 있습니다.
이렇게 하면 모델이 다운로드되는 것을

100
00:02:25,030 --> 00:02:25,040
이렇게 하면 모델이 다운로드되는 것을

101
00:02:25,040 --> 00:02:28,630
이렇게 하면 모델이 다운로드되는 것을
보장할 수 있지만 사이트에서

102
00:02:28,630 --> 00:02:28,640
보장할 수 있지만 사이트에서

103
00:02:28,640 --> 00:02:33,110
보장할 수 있지만 사이트에서
가입하거나 동의를

104
00:02:33,110 --> 00:02:33,120
가입하거나 동의를

105
00:02:33,120 --> 00:02:35,910
가입하거나 동의를
승인해야 합니다. 그것은

106
00:02:35,910 --> 00:02:35,920
승인해야 합니다. 그것은

107
00:02:35,920 --> 00:02:38,550
승인해야 합니다. 그것은
Hugging Face에서 완료됩니다. 완료되면

108
00:02:38,550 --> 00:02:38,560
Hugging Face에서 완료됩니다. 완료되면

109
00:02:38,560 --> 00:02:40,949
Hugging Face에서 완료됩니다. 완료되면
데이터셋을 트리플렛으로

110
00:02:40,949 --> 00:02:40,959
데이터셋을 트리플렛으로

111
00:02:40,959 --> 00:02:43,030
데이터셋을 트리플렛으로
준비해야 합니다. 데이터셋에서

112
00:02:43,030 --> 00:02:43,040
준비해야 합니다. 데이터셋에서

113
00:02:43,040 --> 00:02:46,710
준비해야 합니다. 데이터셋에서
load_dataset을 import하고

114
00:02:46,710 --> 00:02:46,720
load_dataset을 import하고

115
00:02:46,720 --> 00:02:50,070
load_dataset을 import하고
트리플렛이라는 커스텀 함수를 만들겠습니다.

116
00:02:50,070 --> 00:02:50,080
트리플렛이라는 커스텀 함수를 만들겠습니다.

117
00:02:50,080 --> 00:02:52,869
트리플렛이라는 커스텀 함수를 만들겠습니다.
이는 두 개의 문장과 하나의 부정

118
00:02:52,869 --> 00:02:52,879
이는 두 개의 문장과 하나의 부정

119
00:02:52,879 --> 00:02:55,430
이는 두 개의 문장과 하나의 부정
문장을 받을 것입니다. 이 데이터셋에서

120
00:02:55,430 --> 00:02:55,440
문장을 받을 것입니다. 이 데이터셋에서

121
00:02:55,440 --> 00:02:58,070
문장을 받을 것입니다. 이 데이터셋에서
두 문장과 그들의 유사성

122
00:02:58,070 --> 00:02:58,080
두 문장과 그들의 유사성

123
00:02:58,080 --> 00:03:00,070
두 문장과 그들의 유사성
거리를 얻을 것입니다.

124
00:03:00,070 --> 00:03:00,080
거리를 얻을 것입니다.

125
00:03:00,080 --> 00:03:01,990
거리를 얻을 것입니다.

126
00:03:01,990 --> 00:03:02,000
거리를 얻을 것입니다.

127
00:03:02,000 --> 00:03:05,190
유사한 문장은 거리가 더 짧을 것임을

128
00:03:05,190 --> 00:03:05,200
유사한 문장은 거리가 더 짧을 것임을

129
00:03:05,200 --> 00:03:07,350
유사한 문장은 거리가 더 짧을 것임을
알고 있으므로,

130
00:03:07,350 --> 00:03:07,360
알고 있으므로,

131
00:03:07,360 --> 00:03:10,309
알고 있으므로,
유사성이 높은 곳에서 무작위로

132
00:03:10,309 --> 00:03:10,319
유사성이 높은 곳에서 무작위로

133
00:03:10,319 --> 00:03:13,430
유사성이 높은 곳에서 무작위로
세 번째 문장을 준비해보겠습니다.

134
00:03:13,430 --> 00:03:13,440
세 번째 문장을 준비해보겠습니다.

135
00:03:13,440 --> 00:03:16,470
세 번째 문장을 준비해보겠습니다.
이제 조건을 만들고

136
00:03:16,470 --> 00:03:16,480
이제 조건을 만들고

137
00:03:16,480 --> 00:03:21,350
이제 조건을 만들고
부정 문장을 가져오겠습니다.

138
00:03:21,350 --> 00:03:21,360
부정 문장을 가져오겠습니다.

139
00:03:21,360 --> 00:03:24,949
부정 문장을 가져오겠습니다.
여기서 트리플렛 앵커와 포지티브는

140
00:03:24,949 --> 00:03:24,959
여기서 트리플렛 앵커와 포지티브는

141
00:03:24,959 --> 00:03:26,869
여기서 트리플렛 앵커와 포지티브는
같지만 부정 문장으로는

142
00:03:26,869 --> 00:03:26,879
같지만 부정 문장으로는

143
00:03:26,879 --> 00:03:29,270
같지만 부정 문장으로는
거리가 먼 임베딩을 가지게 됩니다.

144
00:03:29,270 --> 00:03:29,280
거리가 먼 임베딩을 가지게 됩니다.

145
00:03:29,280 --> 00:03:32,070
거리가 먼 임베딩을 가지게 됩니다.
완료되면 데이터셋에서

146
00:03:32,070 --> 00:03:32,080
완료되면 데이터셋에서

147
00:03:32,080 --> 00:03:36,390
완료되면 데이터셋에서
이것을 로드하고 dev, test,

148
00:03:36,390 --> 00:03:36,400
이것을 로드하고 dev, test,

149
00:03:36,400 --> 00:03:39,670
이것을 로드하고 dev, test,
train 트리플렛을 준비할 것입니다.

150
00:03:39,670 --> 00:03:39,680
train 트리플렛을 준비할 것입니다.

151
00:03:39,680 --> 00:03:41,990
train 트리플렛을 준비할 것입니다.
이것을 출력해서 데이터셋

152
00:03:41,990 --> 00:03:42,000
이것을 출력해서 데이터셋

153
00:03:42,000 --> 00:03:45,110
이것을 출력해서 데이터셋
준비가 어떻게 되고 있는지

154
00:03:45,110 --> 00:03:45,120
준비가 어떻게 되고 있는지

155
00:03:45,120 --> 00:03:48,470
준비가 어떻게 되고 있는지
확인해보겠습니다.

156
00:03:48,470 --> 00:03:48,480
확인해보겠습니다.

157
00:03:48,480 --> 00:03:50,949
확인해보겠습니다.
여기서 보시는 바와 같이 훈련용 데이터셋은

158
00:03:50,949 --> 00:03:50,959
여기서 보시는 바와 같이 훈련용 데이터셋은

159
00:03:50,959 --> 00:03:54,390
여기서 보시는 바와 같이 훈련용 데이터셋은
약 1,000개의 예제를 가지고 있고

160
00:03:54,390 --> 00:03:54,400
약 1,000개의 예제를 가지고 있고

161
00:03:54,400 --> 00:03:57,190
약 1,000개의 예제를 가지고 있고
dev와 test는 100, 200, 200개씩 가지고 있습니다.

162
00:03:57,190 --> 00:03:57,200
dev와 test는 100, 200, 200개씩 가지고 있습니다.

163
00:03:57,200 --> 00:03:59,990
dev와 test는 100, 200, 200개씩 가지고 있습니다.
앵커, 포지티브, 네거티브를 가지고 있고

164
00:03:59,990 --> 00:04:00,000
앵커, 포지티브, 네거티브를 가지고 있고

165
00:04:00,000 --> 00:04:03,750
앵커, 포지티브, 네거티브를 가지고 있고
훈련 세트의 예제 중 하나를 보면

166
00:04:03,750 --> 00:04:03,760
훈련 세트의 예제 중 하나를 보면

167
00:04:03,760 --> 00:04:06,710
훈련 세트의 예제 중 하나를 보면
"비행기가 이륙하고 있다"처럼 말입니다.

168
00:04:06,710 --> 00:04:06,720
"비행기가 이륙하고 있다"처럼 말입니다.

169
00:04:06,720 --> 00:04:09,509
"비행기가 이륙하고 있다"처럼 말입니다.
포지티브는 "항공기가 이륙하고 있다"이고

170
00:04:09,509 --> 00:04:09,519
포지티브는 "항공기가 이륙하고 있다"이고

171
00:04:09,519 --> 00:04:11,670
포지티브는 "항공기가 이륙하고 있다"이고
네거티브는 "모자를 쓴 젊은이"입니다.

172
00:04:11,670 --> 00:04:11,680
네거티브는 "모자를 쓴 젊은이"입니다.

173
00:04:11,680 --> 00:04:17,110
네거티브는 "모자를 쓴 젊은이"입니다.
이는 의미가 있습니다. 이제

174
00:04:17,110 --> 00:04:17,120
이는 의미가 있습니다. 이제

175
00:04:17,120 --> 00:04:19,270
이는 의미가 있습니다. 이제
STS인 태스크 이름을 정의해야 합니다.

176
00:04:19,270 --> 00:04:19,280
STS인 태스크 이름을 정의해야 합니다.

177
00:04:19,280 --> 00:04:22,790
STS인 태스크 이름을 정의해야 합니다.
이 태스크 이름은 모델로 전달되어

178
00:04:22,790 --> 00:04:22,800
이 태스크 이름은 모델로 전달되어

179
00:04:22,800 --> 00:04:26,710
이 태스크 이름은 모델로 전달되어
이 쿼리를 임베딩으로 인코딩하고

180
00:04:26,710 --> 00:04:26,720
이 쿼리를 임베딩으로 인코딩하고

181
00:04:26,720 --> 00:04:30,710
이 쿼리를 임베딩으로 인코딩하고
또한 우리가 준비하고 있는 문서들을

182
00:04:30,710 --> 00:04:30,720
또한 우리가 준비하고 있는 문서들을

183
00:04:30,720 --> 00:04:33,430
또한 우리가 준비하고 있는 문서들을
위해 사용됩니다. 그 다음에는

184
00:04:33,430 --> 00:04:33,440
위해 사용됩니다. 그 다음에는

185
00:04:33,440 --> 00:04:35,350
위해 사용됩니다. 그 다음에는
쿼리와 문서 사이의

186
00:04:35,350 --> 00:04:35,360
쿼리와 문서 사이의

187
00:04:35,360 --> 00:04:38,230
쿼리와 문서 사이의
유사성을 계산해야 합니다.

188
00:04:38,230 --> 00:04:38,240
유사성을 계산해야 합니다.

189
00:04:38,240 --> 00:04:42,070
유사성을 계산해야 합니다.
이 유사성은 둘이 얼마나 관련이 있는지

190
00:04:42,070 --> 00:04:42,080
이 유사성은 둘이 얼마나 관련이 있는지

191
00:04:42,080 --> 00:04:44,550
이 유사성은 둘이 얼마나 관련이 있는지
알려줄 것입니다. 여기 보시면 음식

192
00:04:44,550 --> 00:04:44,560
알려줄 것입니다. 여기 보시면 음식

193
00:04:44,560 --> 00:04:47,749
알려줄 것입니다. 여기 보시면 음식
예제를 하나 작성했는데 아침식사가

194
00:04:47,749 --> 00:04:47,759
예제를 하나 작성했는데 아침식사가

195
00:04:47,759 --> 00:04:50,230
예제를 하나 작성했는데 아침식사가
나머지 둘에 비해 더 높은 임베딩,

196
00:04:50,230 --> 00:04:50,240
나머지 둘에 비해 더 높은 임베딩,

197
00:04:50,240 --> 00:04:52,790
나머지 둘에 비해 더 높은 임베딩,
낮은 임베딩 거리를 가져야 합니다.

198
00:04:52,790 --> 00:04:52,800
낮은 임베딩 거리를 가져야 합니다.

199
00:04:52,800 --> 00:04:56,870
낮은 임베딩 거리를 가져야 합니다.
실행해보겠습니다.

200
00:04:56,870 --> 00:04:56,880
실행해보겠습니다.

201
00:04:56,880 --> 00:05:00,150
실행해보겠습니다.
보시는 바와 같이 베이스 모델 자체에서

202
00:05:00,150 --> 00:05:00,160
보시는 바와 같이 베이스 모델 자체에서

203
00:05:00,160 --> 00:05:03,510
보시는 바와 같이 베이스 모델 자체에서
꽤 잘 작동하고 있습니다. 예를 들어

204
00:05:03,510 --> 00:05:03,520
꽤 잘 작동하고 있습니다. 예를 들어

205
00:05:03,520 --> 00:05:06,790
꽤 잘 작동하고 있습니다. 예를 들어
만약 당신이 이제 자신만의

206
00:05:06,790 --> 00:05:06,800
만약 당신이 이제 자신만의

207
00:05:06,800 --> 00:05:09,270
만약 당신이 이제 자신만의
데이터셋에 파인튜닝하고 싶다면

208
00:05:09,270 --> 00:05:09,280
데이터셋에 파인튜닝하고 싶다면

209
00:05:09,280 --> 00:05:10,950
데이터셋에 파인튜닝하고 싶다면
sentence transformers 트레이너를

210
00:05:10,950 --> 00:05:10,960
sentence transformers 트레이너를

211
00:05:10,960 --> 00:05:13,909
sentence transformers 트레이너를
사용해야 합니다.

212
00:05:13,909 --> 00:05:13,919
사용해야 합니다.

213
00:05:13,919 --> 00:05:16,870
사용해야 합니다.
그리고 거기서 구성 가능한 인수와

214
00:05:16,870 --> 00:05:16,880
그리고 거기서 구성 가능한 인수와

215
00:05:16,880 --> 00:05:19,590
그리고 거기서 구성 가능한 인수와
손실 함수는 multiple negative ranking loss를

216
00:05:19,590 --> 00:05:19,600
손실 함수는 multiple negative ranking loss를

217
00:05:19,600 --> 00:05:21,510
손실 함수는 multiple negative ranking loss를
전달해야 하며 이는 손실을 준비하는

218
00:05:21,510 --> 00:05:21,520
전달해야 하며 이는 손실을 준비하는

219
00:05:21,520 --> 00:05:23,909
전달해야 하며 이는 손실을 준비하는
모델을 전달해야 합니다.

220
00:05:23,909 --> 00:05:23,919
모델을 전달해야 합니다.

221
00:05:23,919 --> 00:05:27,830
모델을 전달해야 합니다.
이들이 우리가 STS 태스크와 함께

222
00:05:27,830 --> 00:05:27,840
이들이 우리가 STS 태스크와 함께

223
00:05:27,840 --> 00:05:30,469
이들이 우리가 STS 태스크와 함께
프롬프트를 사용해야 하는 인수들입니다.

224
00:05:30,469 --> 00:05:30,479
프롬프트를 사용해야 하는 인수들입니다.

225
00:05:30,479 --> 00:05:32,870
프롬프트를 사용해야 하는 인수들입니다.
이것을 1 에폭 동안 실행하겠고

226
00:05:32,870 --> 00:05:32,880
이것을 1 에폭 동안 실행하겠고

227
00:05:32,880 --> 00:05:35,110
이것을 1 에폭 동안 실행하겠고
학습률은 매우 작으며

228
00:05:35,110 --> 00:05:35,120
학습률은 매우 작으며

229
00:05:35,120 --> 00:05:37,350
학습률은 매우 작으며
weights and bias에 이것을

230
00:05:37,350 --> 00:05:37,360
weights and bias에 이것을

231
00:05:37,360 --> 00:05:41,270
weights and bias에 이것을
보고하지 않을 것입니다. 그렇지 않으면

232
00:05:41,270 --> 00:05:41,280
보고하지 않을 것입니다. 그렇지 않으면

233
00:05:41,280 --> 00:05:43,350
보고하지 않을 것입니다. 그렇지 않으면
거기에 넣으면 weights and bias에

234
00:05:43,350 --> 00:05:43,360
거기에 넣으면 weights and bias에

235
00:05:43,360 --> 00:05:45,029
거기에 넣으면 weights and bias에
로그인해야 합니다.

236
00:05:45,029 --> 00:05:45,039
로그인해야 합니다.

237
00:05:45,039 --> 00:05:48,550
로그인해야 합니다.
이제 이것은 커스텀 콜백으로 훈련 종료 시

238
00:05:48,550 --> 00:05:48,560
이제 이것은 커스텀 콜백으로 훈련 종료 시

239
00:05:48,560 --> 00:05:51,029
이제 이것은 커스텀 콜백으로 훈련 종료 시
평가를 수행하며 평가 함수를

240
00:05:51,029 --> 00:05:51,039
평가를 수행하며 평가 함수를

241
00:05:51,039 --> 00:05:54,310
평가를 수행하며 평가 함수를
호출할 것입니다.

242
00:05:54,310 --> 00:05:54,320
호출할 것입니다.

243
00:05:54,320 --> 00:05:56,950
호출할 것입니다.
평가 함수는 위에서 실행한

244
00:05:56,950 --> 00:05:56,960
평가 함수는 위에서 실행한

245
00:05:56,960 --> 00:05:59,830
평가 함수는 위에서 실행한
쿼리와 문서와 같은 것입니다.

246
00:05:59,830 --> 00:05:59,840
쿼리와 문서와 같은 것입니다.

247
00:05:59,840 --> 00:06:01,510
쿼리와 문서와 같은 것입니다.

248
00:06:01,510 --> 00:06:01,520


249
00:06:01,520 --> 00:06:04,070
여기 보시면 이것이 평가 중에

250
00:06:04,070 --> 00:06:04,080
여기 보시면 이것이 평가 중에

251
00:06:04,080 --> 00:06:05,990
여기 보시면 이것이 평가 중에
실행될 것입니다.

252
00:06:05,990 --> 00:06:06,000
실행될 것입니다.

253
00:06:06,000 --> 00:06:09,029
실행될 것입니다.

254
00:06:09,029 --> 00:06:09,039


255
00:06:09,039 --> 00:06:10,790
평가.

256
00:06:10,790 --> 00:06:10,800
평가.

257
00:06:10,800 --> 00:06:14,230
평가.
완료되면 훈련을 시작하고

258
00:06:14,230 --> 00:06:14,240
완료되면 훈련을 시작하고

259
00:06:14,240 --> 00:06:17,670
완료되면 훈련을 시작하고
모델 인수, 데이터셋, 손실 함수

260
00:06:17,670 --> 00:06:17,680
모델 인수, 데이터셋, 손실 함수

261
00:06:17,680 --> 00:06:20,469
모델 인수, 데이터셋, 손실 함수
그리고 콜백이 무엇인지를 전달할 수 있습니다.

262
00:06:20,469 --> 00:06:20,479
그리고 콜백이 무엇인지를 전달할 수 있습니다.

263
00:06:20,479 --> 00:06:24,230
그리고 콜백이 무엇인지를 전달할 수 있습니다.
실행해보고 어떻게 작동하는지

264
00:06:24,230 --> 00:06:24,240
실행해보고 어떻게 작동하는지

265
00:06:24,240 --> 00:06:26,070
실행해보고 어떻게 작동하는지
확인해보겠습니다.

266
00:06:26,070 --> 00:06:26,080
확인해보겠습니다.

267
00:06:26,080 --> 00:06:28,309
확인해보겠습니다.
이미 실행해봤는데 지금

268
00:06:28,309 --> 00:06:28,319
이미 실행해봤는데 지금

269
00:06:28,319 --> 00:06:31,270
이미 실행해봤는데 지금
다시 실행하겠습니다. 그리고

270
00:06:31,270 --> 00:06:31,280
다시 실행하겠습니다. 그리고

271
00:06:31,280 --> 00:06:33,430
다시 실행하겠습니다. 그리고
GPU 소비가 증가하기

272
00:06:33,430 --> 00:06:33,440
GPU 소비가 증가하기

273
00:06:33,440 --> 00:06:36,710
GPU 소비가 증가하기
시작하는 것을 볼 수 있습니다.

274
00:06:36,710 --> 00:06:36,720
시작하는 것을 볼 수 있습니다.

275
00:06:36,720 --> 00:06:39,990
시작하는 것을 볼 수 있습니다.
1분 정도 기다려보겠습니다.

276
00:06:39,990 --> 00:06:40,000
1분 정도 기다려보겠습니다.

277
00:06:40,000 --> 00:06:42,150
1분 정도 기다려보겠습니다.
여기서 약 1분 정도

278
00:06:42,150 --> 00:06:42,160
여기서 약 1분 정도

279
00:06:42,160 --> 00:06:46,309
여기서 약 1분 정도
걸릴 것입니다.

280
00:06:46,309 --> 00:06:46,319
걸릴 것입니다.

281
00:06:46,319 --> 00:06:48,150
걸릴 것입니다.
훈련 후에 모델을 저장할 것이고

282
00:06:48,150 --> 00:06:48,160
훈련 후에 모델을 저장할 것이고

283
00:06:48,160 --> 00:06:50,309
훈련 후에 모델을 저장할 것이고
그러면 서버에서 추론을 하거나

284
00:06:50,309 --> 00:06:50,319
그러면 서버에서 추론을 하거나

285
00:06:50,319 --> 00:06:52,790
그러면 서버에서 추론을 하거나
사용 사례에 맞게 로컬에서

286
00:06:52,790 --> 00:06:52,800
사용 사례에 맞게 로컬에서

287
00:06:52,800 --> 00:06:55,029
사용 사례에 맞게 로컬에서
호스팅하는 데 사용할 수 있습니다.

288
00:06:55,029 --> 00:06:55,039
호스팅하는 데 사용할 수 있습니다.

289
00:06:55,039 --> 00:06:58,790
호스팅하는 데 사용할 수 있습니다.
이 모델은 모바일 디바이스와

290
00:06:58,790 --> 00:06:58,800
이 모델은 모바일 디바이스와

291
00:06:58,800 --> 00:07:03,430
이 모델은 모바일 디바이스와
레이턴시가 중요하고 리소스

292
00:07:03,430 --> 00:07:03,440
레이턴시가 중요하고 리소스

293
00:07:03,440 --> 00:07:07,510
레이턴시가 중요하고 리소스
제약이 있는 디바이스의 애플리케이션에

294
00:07:07,510 --> 00:07:07,520
제약이 있는 디바이스의 애플리케이션에

295
00:07:07,520 --> 00:07:10,469
제약이 있는 디바이스의 애플리케이션에
매우 유용할 것입니다.

296
00:07:10,469 --> 00:07:10,479
매우 유용할 것입니다.

297
00:07:10,479 --> 00:07:12,790
매우 유용할 것입니다.

298
00:07:12,790 --> 00:07:12,800


299
00:07:12,800 --> 00:07:14,629
유용합니다.

300
00:07:14,629 --> 00:07:14,639
유용합니다.

301
00:07:14,639 --> 00:07:17,749
유용합니다.
이 훈련이 완료되면 이 모델을

302
00:07:17,749 --> 00:07:17,759
이 훈련이 완료되면 이 모델을

303
00:07:17,759 --> 00:07:20,070
이 훈련이 완료되면 이 모델을
사용할 수 있습니다. 이 세션을

304
00:07:20,070 --> 00:07:20,080
사용할 수 있습니다. 이 세션을

305
00:07:20,080 --> 00:07:22,790
사용할 수 있습니다. 이 세션을
시청해주셔서 감사합니다.

306
00:07:22,790 --> 00:07:22,800
시청해주셔서 감사합니다.

307
00:07:22,800 --> 00:07:25,800
시청해주셔서 감사합니다.
정말 감사합니다.


</transcript>