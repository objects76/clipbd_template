1
00:00:00,000 --> 00:00:03,000
여러분 안녕하세요, Adam LK입니다. 오늘은 양자화(quantization)에 대해 이야기해 보겠습니다.

2
00:00:03,000 --> 00:00:08,000
아마도 엔비디아의 이 3.1 네오트론(Neotron) 모델처럼

3
00:00:08,000 --> 00:00:14,000
대형 모델을 살펴본 적이 있다면, 파라미터 수가 약 706억 개

4
00:00:14,000 --> 00:00:19,000
정도라는 걸 보셨을 거예요. 그리고 이 파일들이 상당한 용량을 차지합니다.

5
00:00:19,000 --> 00:00:24,000
보시면 세이프 텐서(safetensors) 파일이 약 30개 있고,

6
00:00:24,000 --> 00:00:29,000
각각이 약 5GB 정도예요. 그런데

7
00:00:29,000 --> 00:00:34,000
모델 카드 페이지로 돌아가 보면,

8
00:00:34,000 --> 00:00:41,000
여기에 양자화된(quantized) 버전들이 있다는 걸 볼 수 있습니다. 예를 들어

9
00:00:41,000 --> 00:00:45,000
bitsandbytes의 4비트 버전(unsloth/… 같은)을 볼 수 있는데,

10
00:00:45,000 --> 00:00:49,000
이제 파라미터 수가 374억 개 정도이고,

11
00:00:49,000 --> 00:00:53,000
여기에는 세이프 텐서 파일이 8개만 있으며,

12
00:00:53,000 --> 00:00:57,000
각각 역시 약 5GB 정도입니다. 즉, 이

13
00:00:57,000 --> 00:01:02,000
기본(base) 모델과 방금 살펴본 모델 사이에 어떤 변환이 일어났고,

14
00:01:02,000 --> 00:01:07,000
그 변환을 우리가 ‘양자화(quantization)’라고 부릅니다. 넓은 의미로는

15
00:01:07,000 --> 00:01:11,000
큰 집합의 입력 값을 셀 수 있거나 더 작은 집합의 출력 값으로

16
00:01:11,000 --> 00:01:15,000
대응시키는(map) 과정을 말합니다. 딥러닝과 머신러닝 맥락에서는,

17
00:01:15,000 --> 00:01:19,000
양자화는 모델의 추론(inference)을 실행할 때의 계산 및 메모리 비용을

18
00:01:19,000 --> 00:01:24,000
줄이기 위해 내부 가중치와 활성값(activations)을 더 낮은 정밀도의

19
00:01:24,000 --> 00:01:29,000
데이터 타입으로 표현하는 기법을 의미합니다. 그리고 양자화는

20
00:01:29,000 --> 00:01:34,000
언어 모델 같은 분야에서, 이렇게 파라미터가 매우 많은 초대형 모델을

21
00:01:34,000 --> 00:01:39,000
더 다루기 쉬운 형식으로 줄여서

22
00:01:39,000 --> 00:01:45,000
소비자용 하드웨어에서 실제로 돌리기 쉽게 해줍니다.

23
00:01:45,000 --> 00:01:49,000
모든 사람이 이러한 모델을 완전한 용량으로 로드하고 실행하는 데 필요한

24
00:01:49,000 --> 00:01:56,000
인프라나 GPU 클러스터를 갖추고 있지는 않으니까요. 그래서 보통 이 변환은

25
00:01:56,000 --> 00:02:01,000
VRAM이나 메모리 요구사항을 낮춰서 더 접근하기 쉬운

26
00:02:01,000 --> 00:02:08,000
혹은 저렴한 하드웨어, 심지어 CPU에서도 실행할 수 있도록 하기 위해 수행됩니다.

27
00:02:08,000 --> 00:02:12,000
그리고 이것이, 소비자급 하드웨어에서 최신 대형 언어 모델을 변환해

28
00:02:12,000 --> 00:02:18,000
실행할 수 있게 해주는 OLLAMA(올라마)나 LM Studio 같은

29
00:02:18,000 --> 00:02:22,000
인기 프로그램들이 가능한 이유죠(이 부분은 뒤에서 더 다룹니다). 예를 들어

30
00:02:22,000 --> 00:02:26,000
올라마의 Llama 3.2 사례를 보면,

31
00:02:26,000 --> 00:02:32,000
Q4\_K\_M으로 양자화해 두었습니다. 이것이

32
00:02:32,000 --> 00:02:37,000
양자화가 무엇을 하는지 이해하려면,

33
00:02:37,000 --> 00:02:43,000
언어 모델 내부 가중치가 실제로 어떻게 저장되는지 살펴봐야 합니다.

34
00:02:43,000 --> 00:02:49,000
몇 주 전에 제가 파인튜닝했던 Llama 3.2 1B 모델을 보면,

35
00:02:49,000 --> 00:02:54,000
각 내부 레이어의 정밀도(precision)가

36
00:02:54,000 --> 00:02:59,000
F16, 즉 float16(반정밀도)로 표시되어 있음을 확인할 수 있습니다.

37
00:02:59,000 --> 00:03:04,000
한 단계 더 들어가, 모델 안의 텐서 하나를 열어 보면

38
00:03:04,000 --> 00:03:11,000
가중치가 이런 식으로 저장되어 있는 걸 볼 수 있어요. 즉,

39
00:03:11,000 --> 00:03:16,000
2048×2048 크기의 거대한 배열 속 수치들이죠. 하지만

40
00:03:16,000 --> 00:03:22,000
이 원래 가중치와 텐서를 그대로 숫자 형태로 출력하는 방식이,

41
00:03:22,000 --> 00:03:27,000
GPU VRAM이나 파일에 실제로 저장/로드되는 방식과

42
00:03:27,000 --> 00:03:30,000
완전히 동일한 건 아닙니다. 내부적으로는 이 숫자들이

43
00:03:30,000 --> 00:03:35,000
이진(binary) 표현으로 저장되죠.

44
00:03:35,000 --> 00:03:39,000
컴퓨터는 이진을 더 잘 다루지만,

45
00:03:39,000 --> 00:03:43,000
우리는 일반적으로 10진수(십진수) 체계를 씁니다. 즉,

46
00:03:43,000 --> 00:03:49,000
위치적 표기법을 사용하는 10진수 체계인데,

47
00:03:49,000 --> 00:03:57,000
예를 들어 254라는 숫자가 있으면, 각 자릿수의 위치에 따라

48
00:03:57,000 --> 00:04:04,000
다르게 표현할 수 있습니다. 맨 오른쪽(0번째 자리)의 4는

49
00:04:04,000 --> 00:04:09,000
4 × 10^0, 즉 4 × 1 = 4가 되고,

50
00:04:09,000 --> 00:04:19,000
그다음 자리의 5는 5 × 10^1 = 50,

51
00:04:19,000 --> 00:04:25,000
그다음 2는 2 × 10^2 = 200이 되죠.

52
00:04:25,000 --> 00:04:30,000
이걸 모두 더하면 254가 됩니다.

53
00:04:30,000 --> 00:04:35,000
하지만 컴퓨터에서 10진수를 다루는 건 조금 더 복잡합니다. 컴퓨터는

54
00:04:35,000 --> 00:04:41,000
대부분의 경우 참/거짓처럼 이진적인 것을 선호하고,

55
00:04:41,000 --> 00:04:44,000
하드웨어는 신호를 켜짐/꺼짐(on/off)으로 읽는 게 일반적이죠. 그래서

56
00:04:44,000 --> 00:04:49,000
0과 1로 표현되는 비트(이진 숫자)로 수를 표현하는 게

57
00:04:49,000 --> 00:04:55,000
현대 컴퓨팅에서 보편화되었습니다. 이진수는

58
00:04:55,000 --> 00:05:00,000
10진수가 아니라, 기수 2인 체계입니다. 예를 들어

59
00:05:00,000 --> 00:05:07,000
8자리의 이진수 11111110을 보자면,

60
00:05:07,000 --> 00:05:11,000
10진수 때와 비슷하게 자릿값을 펼칠 수 있어요. 첫 번째 자리(오른쪽부터)

61
00:05:11,000 --> 00:05:25,000
는 2^0 × 0, 다음은 2^1 × 1, …

62
00:05:25,000 --> 00:05:34,000
그다음은 2^2 × 1, 이런 식으로 지수들이 쭉 늘어서고,

63
00:05:34,000 --> 00:05:40,000
모두 더하면 아까의 254가 됩니다.

64
00:05:40,000 --> 00:05:46,000
즉, 같은 수를 기수 2의 이진 표기로 바꾼 거죠. 그리고

65
00:05:46,000 --> 00:05:51,000
소수(분수)도 처리할 수 있습니다. 소수점 오른쪽은

66
00:05:51,000 --> 00:05:57,000
-1부터 음의 지수로 내려가요(-∞까지). 전체 수식을

67
00:05:57,000 --> 00:06:00,000
전부 다 쓰는 건 생략하겠지만,

68
00:06:00,000 --> 00:06:05,000
예를 들어 101.11(2) 같은 이진수가 있으면,

69
00:06:05,000 --> 00:06:10,000
앞의 세 자리(101)는 정수 부분, 소수점 오른쪽 두 자리(.11)는

70
00:06:10,000 --> 00:06:17,000
각각 2^-1, 2^-2에 해당해요. 이를 10진수로 바꾸면 0.75가 되고,

71
00:06:17,000 --> 00:06:24,000
전체는 5.75가 됩니다. 즉, 5.75의 이진 표현이죠.

72
00:06:24,000 --> 00:06:28,000
다만, 언어 모델 가중치처럼 실제로 모델을 구성하는

73
00:06:28,000 --> 00:06:33,000
‘날 것의’ 숫자들이 이진으로만 저장되는 게 아니라,

74
00:06:33,000 --> 00:06:38,000
일정한 ‘정밀도(precision)’ 방식으로 저장됩니다. 여기서 말하는 정밀도란,

75
00:06:38,000 --> 00:06:42,000
부동소수점(floating point)을 의미해요. 부동소수점은

76
00:06:42,000 --> 00:06:48,000
과학적 표기법을 이진에 적용한 것과 비슷한데,

77
00:06:48,000 --> 00:06:53,000
10의 거듭제곱 대신 2의 거듭제곱을 사용합니다. 왜냐하면

78
00:06:53,000 --> 00:06:57,000
우리는 10진수 대신 이진을 다루고 있으니까요. 부동소수점은

79
00:06:57,000 --> 00:07:01,000
한정된 비트 수로 수를 효율적으로 표현하려는 필요에서 나왔습니다.

80
00:07:01,000 --> 00:07:07,000
즉, 컴퓨터 연산에서 대부분 필요한 숫자들을

81
00:07:07,000 --> 00:07:12,000
고작 32비트로 나타내기 위한 방법이죠.

82
00:07:12,000 --> 00:07:19,000
딥러닝 모델의 가중치 숫자들도 이런 부동소수점으로 저장됩니다.

83
00:07:19,000 --> 00:07:33,000
가장 흔하고 표준적인 건 IEEE 754 단정밀도(single-precision) 32비트 float이며,

84
00:07:33,000 --> 00:07:38,000
말 그대로 32비트 이진수에서

85
00:07:38,000 --> 00:07:43,000
첫 비트는 부호(sign), 다음 8비트는 지수(exponent),

86
00:07:43,000 --> 00:07:48,000
마지막 23비트는 가수(fraction, mantissa, significand)입니다.

87
00:07:48,000 --> 00:07:53,000
이 이진 부동소수점과 10진수 간의 변환 공식은

88
00:07:53,000 --> 00:07:58,000
대략 이렇게 생겼는데, 실제 변환 예시를 보면 더 이해하기 쉽습니다.

89
00:07:58,000 --> 00:08:02,000
아까의 5.75를 예로 들어보면,

90
00:08:02,000 --> 00:08:07,000
먼저 이를 이진으로 바꿔야 하죠(조금 전에 했던 것처럼)

91
00:08:07,000 --> 00:08:12,000
5.75(10) = 101.11(2)입니다. 이를 정규화(normalize)하면

92
00:08:12,000 --> 00:08:15,000
1.011 × 2^2 형태가 됩니다. 이는

93
00:08:15,000 --> 00:08:24,000
10진 과학적 표기법과 매우 유사합니다.

94
00:08:24,000 --> 00:08:28,000
이 수를 세 부분으로 나누면, 부호는 양수이므로 0(양수=0, 음수=1),

95
00:08:28,000 --> 00:08:32,000
지수는 2(여기서 ^2),

96
00:08:32,000 --> 00:08:38,000
가수(유효숫자)는 1.0111…이 됩니다.

97
00:08:38,000 --> 00:08:43,000
여기서 지수에는 127의 바이어스(bias)를 더합니다. 즉, 2 + 127 = 129.

98
00:08:43,000 --> 00:08:48,000
그 이유는, 8비트 지수는 0\~255를 표현할 수 있지만,

99
00:08:48,000 --> 00:09:01,000
큰 양수와 작은 분수(정밀도)를 모두 표현하고 싶기 때문입니다.

100
00:09:01,000 --> 00:09:07,000
그래서 127을 기준으로 양수/음수 지수 범위를 균형 있게 배분하죠.

101
00:09:07,000 --> 00:09:14,000
따라서 지수는 129가 되고, 이를 이진으로 바꾸면

102
00:09:14,000 --> 00:09:20,000
10000001(2)이 됩니다(설명상 앞뒤 숫자 간 공백은 가독성 때문).

103
00:09:20,000 --> 00:09:24,000
부호 비트 0과 함께 부호·지수 부분이 정해졌고,

104
00:09:24,000 --> 00:09:30,000
이제 가수 부분을 처리하면 됩니다. 가수는 항상

105
00:09:30,000 --> 00:09:37,000
선행 1(implicit leading 1)을 가정하므로, 소수점 이하만 취해

106
00:09:37,000 --> 00:09:42,000
0111…을 채우고, 남은 비트는 0으로 패딩합니다.

107
00:09:42,000 --> 00:09:48,000
이렇게 부호/지수/가수를 모두 합치면 단정밀도 float32 표현이 완성됩니다.

108
00:09:48,000 --> 00:10:02,000
결과적으로 대부분의 계산에 필요한 수를 32비트(=4바이트)로

109
00:10:02,000 --> 00:10:05,000
표현할 수 있습니다. 하지만

110
00:10:05,000 --> 00:10:10,000
수십억 개의 숫자를 저장해야 하는 대형 모델에서는

111
00:10:10,000 --> 00:10:15,000
총 용량이 엄청나게 불어납니다. 그래서 제 모델에서는

112
00:10:15,000 --> 00:10:20,000
32비트가 아니라 16비트 부동소수점(float16; half precision)을 사용합니다.

113
00:10:20,000 --> 00:10:25,000
half precision은 부호 1비트, 지수 5비트, 가수 10비트이고,

114
00:10:25,000 --> 00:10:30,000
또 딥러닝에서는 BF16(brain float 16)도 많이 씁니다.

115
00:10:30,000 --> 00:10:35,000
BF16은 부호 1비트, 지수 8비트, 가수 7비트죠.

116
00:10:35,000 --> 00:10:40,000
즉, FP32/FP16/BF16이

117
00:10:40,000 --> 00:10:46,000
대부분의 언어 모델이나 심층 신경망이 학습/저장에 사용하는

118
00:10:46,000 --> 00:10:51,000
대표적인 데이터 타입입니다. 이런 높은 정밀도는

119
00:10:51,000 --> 00:10:57,000
학습 중에 포착되는 다양한 뉘앙스와 정보를 담기 위해 필요합니다.

120
00:10:57,000 --> 00:11:00,000
하지만 그만큼 저장 공간을 많이 먹고,

121
00:11:00,000 --> 00:11:05,000
맥북이나 소비자용 GPU에서 돌리기엔 부담스럽죠.

122
00:11:05,000 --> 00:11:10,000
그런데 추론(텍스트 생성)을 할 때는

123
00:11:10,000 --> 00:11:15,000
항상 이런 고정밀도가 필요하지는 않습니다. 충분히 비슷한 품질을

124
00:11:15,000 --> 00:11:19,000
낮은 정밀도로도 얻을 수 있죠. 연구자들은

125
00:11:19,000 --> 00:11:24,000
FP16/BF16을 8비트, 심지어 4비트 같은 더 압축된 표현으로 변환해도

126
00:11:24,000 --> 00:11:28,000
모델 성능을 대부분 유지하면서

127
00:11:28,000 --> 00:11:34,000
모델 크기와 계산량을 크게 줄일 수 있다는 걸 보였습니다.

128
00:11:34,000 --> 00:11:38,000
그래서 양자화가 언어 모델에서 본격적으로 쓰이기 시작했고,

129
00:11:38,000 --> 00:11:41,000
FP16(또는 half) 벡터/텐서를

130
00:11:41,000 --> 00:11:47,000
-127\~127 범위의 int8 벡터로 사상(mapping)하는 등의 방법이

131
00:11:47,000 --> 00:11:53,000
여기서 쓰입니다. 그럼 질문이 생기죠. 이렇게 넓은 범위를 다루는

132
00:11:53,000 --> 00:11:58,000
half precision을 어떻게 고작 255개의 정수로 압축하느냐,

133
00:11:58,000 --> 00:12:03,000
너무 많은 정보가 사라지는 것 아니냐? 하고요.

134
00:12:03,000 --> 00:12:08,000
그럴듯해 보이지만, 실제로 FP16→int8 변환은 생각만큼 나쁘지 않습니다.

135
00:12:08,000 --> 00:12:12,000
그 이유는 추론 시

136
00:12:12,000 --> 00:12:17,000
각 가중치의 ‘절대값’ 그 자체보다,

137
00:12:17,000 --> 00:12:21,000
가중치들 사이의 ‘관계’와 ‘차이’가 더 중요하기 때문입니다.

138
00:12:21,000 --> 00:12:28,000
즉, 알고리즘적으로 효율적인 방식으로 값을 더 작은 표현으로

139
00:12:28,000 --> 00:12:34,000
잘 매핑할 수만 있다면, 성능을 대부분 유지하면서도

140
00:12:34,000 --> 00:12:40,000
모델 크기와 발자국(footprint)을 크게 줄일 수 있습니다.

141
00:12:40,000 --> 00:12:44,000
실험들을 보면 FP16과 int8 양자화본 사이의 차이가

142
00:12:44,000 --> 00:12:52,000
매우 작게 나타난 경우가 많습니다.

143
00:12:52,000 --> 00:12:56,000
더 나아가 4비트(각 숫자를 16가지 값으로 표현)까지 내려가도

144
00:12:56,000 --> 00:13:02,000
아주 준수한 성능을 얻을 수 있었고,

145
00:13:02,000 --> 00:13:09,000
심지어 1비트 양자화까지도 연구 중입니다. 수학/알고리즘 세부는

146
00:13:09,000 --> 00:13:14,000
설명란의 자료를 참고하시면 좋겠고(영상 맥락),

147
00:13:14,000 --> 00:13:19,000
중요한 점은 이미 이런 양자화를 자동으로 해주는

148
00:13:19,000 --> 00:13:24,000
패키지들이 많이 존재한다는 겁니다.

149
00:13:24,000 --> 00:13:28,000
그럼 이제 실제로 이걸 사용하는 법과

150
00:13:28,000 --> 00:13:32,000
모델들을 비교해보겠습니다. 코드로 넘어가면,

151
00:13:32,000 --> 00:13:36,000
제가 만든 10억 파라미터 Llama 3.2 모델을 로드해서

152
00:13:36,000 --> 00:13:40,000
내부를 조금 살펴볼 텐데,

153
00:13:40,000 --> 00:13:45,000
먼저 보여드리고 싶은 건 Transformers에 포함된 bitsandbytes를 이용해

154
00:13:45,000 --> 00:13:51,000
양자화를 적용하는 방법입니다. 기본(base) 모델을 로드할 때는

155
00:13:51,000 --> 00:13:56,000
보통 AutoModelForCausalLM.from\_pretrained 같은 걸 쓰고,

156
00:13:56,000 --> 00:14:00,000
허깅페이스 리포(model\_id)를 넘깁니다. 여기에

157
00:14:00,000 --> 00:14:03,000
quantization\_config를 추가로 전달할 수 있어요.

158
00:14:03,000 --> 00:14:08,000
bitsandbytes 설정을 만들어

159
00:14:08,000 --> 00:14:11,000
load\_in\_8bit=True로 주면 8비트 로드가 되고,

160
00:14:11,000 --> 00:14:17,000
그 설정을 quantization\_config로 넘기면 됩니다.

161
00:14:17,000 --> 00:14:21,000
4비트도 마찬가지이고, 저는 블로그 글(설명에 링크)에 나온

162
00:14:21,000 --> 00:14:26,000
몇 가지 인자를 더 넣었습니다. 로드 직후 용량을 보면,

163
00:14:26,000 --> 00:14:32,000
베이스 모델은 약 4.9×10^9 바이트,

164
00:14:32,000 --> 00:14:36,000
int8 모델은 약 1.5×10^9 바이트,

165
00:14:36,000 --> 00:14:40,000
4비트 모델은 약 1.0×10^9 바이트입니다.

166
00:14:40,000 --> 00:14:45,000
즉, 각각 약 4.9GB, 1.5GB, 1.0GB에 해당하죠.

167
00:14:45,000 --> 00:14:52,000
이미 8비트로 베이스 대비 약 30%, 4비트로는 약 20% 크기로

168
00:14:52,000 --> 00:14:57,000
대폭 줄었습니다. VRAM 요구량을 보면,

169
00:14:57,000 --> 00:15:03,000
이 10억 파라미터 베이스 모델은 약 5GB VRAM이 필요하지만,

170
00:15:03,000 --> 00:15:09,000
8비트는 약 1.7GB, 4비트는 약 1.2GB면 됩니다.

171
00:15:09,000 --> 00:15:13,000
즉, 소비자용 GPU(보통 12GB, 많아야 24GB VRAM) 기준으로

172
00:15:13,000 --> 00:15:20,000
자원 요구량을 80% 가까이 줄일 수 있으니

173
00:15:20,000 --> 00:15:27,000
성능이 비슷하게만 유지된다면 엄청난 이득입니다.

174
00:15:27,000 --> 00:15:31,000
이제 모델을 열어 숫자들을 실제로 보면,

175
00:15:31,000 --> 00:15:34,000
양자화가 어떻게 변환했는지 확인할 수 있습니다. 원래 가중치는

176
00:15:34,000 --> 00:15:38,000
float16(half)였고,

177
00:15:38,000 --> 00:15:47,000
8비트 가중치는 정수 값(대략 -127\~127 범위)으로 보입니다.

178
00:15:47,000 --> 00:15:53,000
4비트 가중치는 구현상 약간 특이하게, 부호 없는 uint8로

179
00:15:53,000 --> 00:15:58,000
보이는데, 이는 8비트 값 하나에 4비트 두 개를

180
00:15:58,000 --> 00:16:03,000
패킹해 두었기 때문입니다. 즉, 8비트를 둘로 쪼개

181
00:16:03,000 --> 00:16:08,000
각각이 4비트 가중치가 되는 방식이죠. 구현 효율을 위한

182
00:16:08,000 --> 00:16:16,000
추가 단계라고 보시면 됩니다. 어쨌든 두 가지 양자화가

183
00:16:16,000 --> 00:16:20,000
제대로 적용되었다고 자신 있게 말할 수 있겠죠.

184
00:16:20,000 --> 00:16:26,000
하지만 양자화의 가치는 결국 모델이 얼마나 잘 동작하느냐에 있습니다.

185
00:16:26,000 --> 00:16:31,000
그래서 각 버전으로 텍스트를 생성해 보겠습니다. 프롬프트는

186
00:16:31,000 --> 00:16:36,000
“What is a language model?(언어 모델이란 무엇인가?)”이고,

187
00:16:36,000 --> 00:16:41,000
세 가지 버전(베이스/8비트/4비트) 모두에 돌려볼게요.

188
00:16:41,000 --> 00:16:45,000
참고로 이건 10억 파라미터 모델이라,

189
00:16:45,000 --> 00:16:49,000
70억 이상 대형 모델만큼 강력하진 않습니다. 그래도

190
00:16:49,000 --> 00:16:56,000
차이는 볼 수 있을 거예요.

191
00:16:56,000 --> 00:17:01,000
세 모델이 생성한 텍스트를 나란히 보면,

192
00:17:01,000 --> 00:17:05,000
베이스 모델은 “텍스트를 생성하는 수학적 모델이며,

193
00:17:05,000 --> 00:17:09,000
NLP, 기계 번역, 음성 인식 등 다양한 애플리케이션에 쓰인다”라고

194
00:17:09,000 --> 00:17:13,000
설명합니다. 8비트 모델도

195
00:17:13,000 --> 00:17:19,000
“텍스트 입력을 텍스트 출력으로 사상하는 수학적 함수”라고 하며,

196
00:17:19,000 --> 00:17:23,000
자연어 처리, 번역에 쓰인다고 하고,

197
00:17:23,000 --> 00:17:27,000
대규모 코퍼스로 학습된다는 점을 덧붙입니다. 4비트 모델도

198
00:17:27,000 --> 00:17:34,000
유사한 내용을, 심지어 더 길게 답하기도 했습니다.

199
00:17:34,000 --> 00:17:38,000
즉, 모델을 크게 압축했음에도

200
00:17:38,000 --> 00:17:45,000
출력 텍스트의 질은 베이스와 거의 구분하기 어려울 정도입니다.

201
00:17:45,000 --> 00:17:49,000
또 ‘퍼플렉서티(perplexity)’라는 흔한 지표로

202
00:17:49,000 --> 00:17:53,000
다음 토큰 예측이 얼마나 잘 되는지 볼 수 있습니다. 이는

203
00:17:53,000 --> 00:17:58,000
모델이 예측에 얼마나 확신(낮은 perplexity) 또는 불확실(높은 perplexity)한지를

204
00:17:58,000 --> 00:18:03,000
나타냅니다. 출력과 정답 간 손실을

205
00:18:03,000 --> 00:18:08,000
계산하는 방식으로 구하죠. 결과를 보면,

206
00:18:08,000 --> 00:18:12,000
베이스의 퍼플렉서티는 약 3.04,

207
00:18:12,000 --> 00:18:18,000
8비트는 약 3.48, 4비트는 약 3.46입니다.

208
00:18:18,000 --> 00:18:23,000
즉, 양자화 모델이 약간 덜 확신하는 편이지만,

209
00:18:23,000 --> 00:18:27,000
베이스와 큰 차이가 나지는 않습니다. 따라서

210
00:18:27,000 --> 00:18:31,000
양자화로 성능이 약간 저하되긴 했지만,

211
00:18:31,000 --> 00:18:37,000
베이스와 상당히 유사한 수준을 유지한다고 말할 수 있습니다.

212
00:18:37,000 --> 00:18:42,000
그렇다면 베이스 대비 크기/자원 요구가 20% 수준인 모델이

213
00:18:42,000 --> 00:18:46,000
성능은 조금만 떨어지는 셈이니,

214
00:18:46,000 --> 00:18:50,000
제한된 하드웨어에서 초대형 모델을 더 널리 쓰게 해주는

215
00:18:50,000 --> 00:18:57,000
유망한 접근임을 보여줍니다.

216
00:18:57,000 --> 00:19:01,000
기본적인 양자화 외에도, GGUF 포맷으로의

217
00:19:01,000 --> 00:19:05,000
변환/양자화를 빼놓을 수 없습니다.

218
00:19:05,000 --> 00:19:09,000
GGUF는 Llama.cpp(Llama C++)의 개발자인

219
00:19:09,000 --> 00:19:13,000
Georgi Gerganov가 만든 포맷으로,

220
00:19:13,000 --> 00:19:19,000
C 언어가 지원되는 거의 모든 하드웨어에서

221
00:19:19,000 --> 00:19:25,000
언어 모델을 효율적으로 로드/실행하기 위한 프레임워크입니다.

222
00:19:25,000 --> 00:19:28,000
GGUF는 모델을 단일 파일로 효율적으로 저장/서빙하도록 설계되었고,

223
00:19:28,000 --> 00:19:33,000
GGUF 리포들을 보면 실제로 단일 .gguf 파일만 있는 경우가 많습니다.

224
00:19:33,000 --> 00:19:38,000
앞서 말했듯 LM Studio나 OLLAMA 같은 곳에서도 인기 있는 포맷이고,

225
00:19:38,000 --> 00:19:43,000
CPU 같은 제한된 자원 환경에서도

226
00:19:43,000 --> 00:19:49,000
양자화된 모델을 효과적으로 실행할 수 있습니다.

227
00:19:49,000 --> 00:19:53,000
Georgi의 Llama.cpp 라이브러리에는

228
00:19:53,000 --> 00:19:58,000
모델을 GGUF로 변환하고 양자화하는 데 필요한 것이 모두 들어 있습니다.

229
00:19:58,000 --> 00:20:03,000
단일 파일로 합치는 것 외에도,

230
00:20:03,000 --> 00:20:08,000
8비트부터 2비트까지 다양한 양자화 방식과,

231
00:20:08,000 --> 00:20:12,000
층별로 조합하는 옵션들이 있습니다. 그중

232
00:20:12,000 --> 00:20:16,000
많이 쓰이는 방식이 Q4\_K\_M인데,

233
00:20:16,000 --> 00:20:21,000
이는 어텐션/피드포워드의 절반은 6비트, 나머지는 4비트 K-quant로

234
00:20:21,000 --> 00:20:26,000
양자화하는 식의 구성입니다.

235
00:20:26,000 --> 00:20:31,000
모델을 이 포맷으로 양자화하려면,

236
00:20:31,000 --> 00:20:35,000
먼저 Llama.cpp 리포를 클론해 빌드하고,

237
00:20:35,000 --> 00:20:39,000
그다음 모델을 허깅페이스에서 받아옵니다.

238
00:20:39,000 --> 00:20:43,000
이후 스크립트(convert-hf-to-gguf)를 사용해

239
00:20:43,000 --> 00:20:46,000
허깅페이스 포맷(safetensors)을

240
00:20:46,000 --> 00:20:50,000
float16 GGUF로 1차 변환합니다. 이 단계는

241
00:20:50,000 --> 00:20:54,000
금방 끝납니다. 그런 다음

242
00:20:54,000 --> 00:20:58,000
선택한 양자화 방식(Q4\_K\_M)을 적용해

243
00:20:58,000 --> 00:21:03,000
GGUF를 양자화합니다. 이 역시 빠르게 진행되고,

244
00:21:03,000 --> 00:21:07,000
곧 완성됩니다. 이렇게

245
00:21:07,000 --> 00:21:11,000
양자화된 모델을 터미널에서 로드해,

246
00:21:11,000 --> 00:21:16,000
예를 들어 “Why is the sky blue?(하늘이 왜 파란가?)” 같은 질문을 해보면,

247
00:21:16,000 --> 00:21:23,000
잘 동작하는 걸 볼 수 있습니다.

248
00:21:23,000 --> 00:21:27,000
이 4비트 GGUF 모델은 앞서 본 것보다도 더 가볍고,

249
00:21:27,000 --> 00:21:31,000
약 800MB 정도에 불과합니다. 게다가

250
00:21:31,000 --> 00:21:34,000
GPU 없이도 구동됩니다. 시스템 RAM에

251
00:21:34,000 --> 00:21:39,000
바로 로드해도 무리 없이 돌아가고,

252
00:21:39,000 --> 00:21:43,000
여전히 준수한 성능을 보여줍니다. 이 모델을 직접 써보고 싶다면

253
00:21:43,000 --> 00:21:48,000
제가 허깅페이스에 업로드해 두었습니다(영상 맥락).

254
00:21:48,000 --> 00:21:52,000
정리하자면, 양자화는

255
00:21:52,000 --> 00:21:57,000
언어 모델을 소비자급 하드웨어에 로드/실행/저장할 때

256
00:21:57,000 --> 00:22:01,000
최적화하려면 반드시 이해해야 할 주제입니다.

257
00:22:01,000 --> 00:22:06,000
성능과 효율의 균형을 맞추는 강력한 기술이고,

258
00:22:06,000 --> 00:22:09,000
고가의 스토리지나 막대한 VRAM 없이도

259
00:22:09,000 --> 00:22:14,000
더 많은 사람이 대형 모델을 사용할 수 있게 해줍니다.

260
00:22:14,000 --> 00:22:18,000
오늘 양자화에 대해 흥미로운 걸 하나라도 배우셨길 바랍니다.

261
00:22:18,000 --> 00:22:21,000
영상이 마음에 드셨다면 좋아요 눌러주시고,

262
00:22:21,000 --> 00:22:25,000
질문이 있다면 댓글로 남겨주세요. 이런 콘텐츠를 더 보고

263
00:22:25,000 --> 00:22:25,000
채널을 응원해 주시려면 구독도 부탁드립니다. 감사합니다,

263
00:22:25,000 --> 00:22:28,000
좋은 하루 보내세요.
